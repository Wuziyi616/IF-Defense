#################### baselines
# train victim models on purely clean data
We provide four victim models: pointnet, pointnet2, dgcnn, pointconv

You need to specify the victim model to train in the command

CUDA_VISIBLE_DEVICES=0 python train.py --model={$MODEL} --num_points=1024

# hybrid training for victim models used in IF-Defense
You need to specify the victim model to train, dataset name and path to data-after-defense in the command
We train a model on both clean and defense data (NOT adv data so this is not adversarial training!)
You can refer to appendix of the paper for more details about hybrid training
$DATASET should be '{$METHOD}_mn40', e.g. remesh_mn40, opt_mn40, conv_opt_mn40
Then, these weights are used as the victim models in evaluating IF-Defense

CUDA_VISIBLE_DEVICES=0 python hybrid_train.py --model={$MODEL} --num_points=1024 --dataset={$DATASET} --def_data=path/to/defense_data.npz

# evaluate model accuracy/attack success rate
You need to specify the victim model to test, mode of testing, dataset and path to test data
Accuracy is reported in normal mode, while accuracy and attack success rate are reported in target mode
It is not necessary to set --normalize_pc=True when testing on adv point clouds

CUDA_VISIBLE_DEVICES=0 python inference.py --num_points=1024 --mode=normal/target --model={$MODEL} --normalize_pc=True/False --dataset={$DATASET} --data_root=path/to/test_data.npz



#################### baseline attacks
# files to conduct attacks are in attack_scripts/
We provide pytorch implementations of 7 attacks:
    Perturb, Add (Point), Add Cluster/Object (not used in the paper), kNN, Drop and variants of FGM (not used in the paper)
The attacks (except for Dropping) are very time-cosuming since they use CW attack framework which requires multi-step binary search or FGM requires many steps of optimization
In order to speed up the attack process, I use torch.nn.parallel.DistributedDataParallel
You need to assign the GPUs index, --nproc_per_node={$NUM_GPU_USED} and a unique master_port
After the attack, the adv data generated by each process (GPU) will be stored separately as npz files
You need to run a merge command to merge them into one npz file

# Perturb
You need to specify the victim model and dataset name in the command
The dataset will specify the victim model weight you conduct attack on
E.g. if you want to try ConvONet-Opt, you can set $DATASET=conv_opt_mn40 to perform the attack and then defense

NCCL_DEBUG=INFO CUDA_VISIBLE_DEVICES=0 python -m torch.distributed.launch --nproc_per_node=1 --master_port=29501 attack_scripts/targeted_perturb_attack.py --model={$MODEL} --num_points=1024 --dataset={$DATASET}

# Add
You need to specify the victim model, distance measurement and dataset name in the command

NCCL_DEBUG=INFO CUDA_VISIBLE_DEVICES=0 python -m torch.distributed.launch --nproc_per_node=1 --master_port=29501 attack_scripts/targeted_add_attack.py --model={$MODEL} --dist_func=chamfer/hausdorff --num_points=1024 --dataset={$DATASET}

# Add Cluster
You need to specify the victim model, number of clusters added, number of points in each cluster and dataset name in the command

NCCL_DEBUG=INFO CUDA_VISIBLE_DEVICES=0 python -m torch.distributed.launch --nproc_per_node=1 --master_port=29501 attack_scripts/targeted_add_cluster_attack.py --num_add=3 --cl_num_p=32 --model={$MODEL} --num_points=1024 --dataset={$DATASET}

# Add Object
You need to specify the victim model, number of objects added, number of points in each object and dataset name in the command

NCCL_DEBUG=INFO CUDA_VISIBLE_DEVICES=0 python -m torch.distributed.launch --nproc_per_node=1 --master_port=29501 attack_scripts/targeted_add_object_attack.py --num_add=3 --obj_num_p=64 --model={$MODEL} --num_points=1024 --dataset={$DATASET}

# kNN
You need to specify the victim model and dataset name in the command

NCCL_DEBUG=INFO CUDA_VISIBLE_DEVICES=0 python -m torch.distributed.launch --nproc_per_node=1 --master_port=29501 attack_scripts/targeted_knn_attack.py --model={$MODEL} --num_points=1024 --dataset={$DATASET}

# FGM
You need to specify the victim model, dataset name, attack_type, budget and number of attack iterations in the command

NCCL_DEBUG=INFO CUDA_VISIBLE_DEVICES=0 python -m torch.distributed.launch --nproc_per_node=1 --master_port=29501 attack_scripts/targeted_fgm_attack.py --model={$MODEL} --attack_type=FGM/IFGM/MIFGM/PGD --budget={$BUDGET} --num_iter={$NUM_ITER} --num_points=1024 --dataset={$DATASET}

# Drop
You need to specify the victim model, dataset name and number of dropped points in the command

CUDA_VISIBLE_DEVICES=0 python attack_scripts/untargeted_drop_attack.py --model={$MODEL} --num_drop=100/200 --num_points=1024 --dataset={$DATASET}

# Merge the attacked npz files
The adv data generated by different process will be stored as:
    'xxx/{$attack_method}-{$victim_model}-success_{$success_rate}-rank_{$process_rank}.npz'
You need to use this command to merge them into one npz file

python util/merge_attack_results.py --data_root='xxx/{$attack_method}-{$victim_model}-success_'

Then, we will concat the adv data, GT and target labels in each npz file into one file
Also, the attack success rate will be summed up
The distributed npz files will be removed, only the new one will remain



#################### baseline defenses
You need to specify a defense method to apply in the command
If not specified, will apply all three methods

CUDA_VISIBLE_DEVICES=0 python defend_npz.py --data_root=path/to/adv_data.npz --defense=srs/sor/dup/''
